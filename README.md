Code for the paper "How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation"

### Folder Structure
    .
    ├── Original_Datasets           # Preprocessed datasets, scripts to generate queries and node mapping, and print network statistics
    ├── Input_Datasets              # Scripts to generate transformed graphs for each algorithms, and corresponding transformed graphs
    ├── Representative_algorithms   # Code to running representative algorithms
    ├── Algorithm_Output            # The inital CS output from representative algorithms
    ├── Cohesiveness_Calculation    # The scripts for calculating structural and psychology-informed cohesiveness, and conducting sensitivity analysis
    ├── Cohesiveness_Output         # Cohesiveness calculation results, the script to condense the results, and the corresponding condensed results
    ├── Visualization               # Scripts for data visualization
    ├── Figures                     # Figures
    └── README.md

### Original_Datasets
1. Original_Dataset (Preprocessed_ver.): The preprocessed four datasets are provided, including llama version and vader version
2. Node_Mapping: The mapping file for tranferring node id between original_id and mapped_id started from index 0 
3. Query_Nodes: Code, query nodes, and mapped query nodes are all provided


### Representative_algorithms
1. The links to all available codebases for representative algorithms can be found in the following table:
    | Type      | Algorithm | Title                                                                                            | Code   |
    |-----------|-----------|--------------------------------------------------------------------------------------------------|--------|
    | *k*-core  | ALS       |[QTCS: Efficient Query-Centered Temporal Community Search](https://github.com/longlonglin/QTCS)   | Python |
    |           | WCF-CRC   |[Reliable community search in dynamic networks](https://github.com/Cyril-Tang/CRC-query)          | Python |
    |           | CSD       |[Efficient community search over large directed graphs: An augmented index-based approach](https://github.com/wzr95/community-search) | Java   |
    | *k*-truss | ST-Exa    |[Size-Constrained Community Search on Large Networks: An Effective and Efficient Solution](https://github.com/harrycoder17/Size-constrained-Community-Search)    | C      |
    |           | Repeeling+|[Truss-Based Community Search over Streaming Directed Graphs](https://github.com/hkbudb/streaming-dtruss)        | C++    |
    |           | I2ACSM    |[Effective influential community search on attributed graph](https://github.com/Smj765/InfluentialAttributeCS)   | Java   |
    | Learning-based  | TransZero_LS & TransZero_GS|[Efficient Unsupervised Community Search with Pre-trained Graph Transformer](https://github.com/guaiyoui/TransZero)            | Python |

2. For each algorithms, only the revised scripts are provided to save the space, with only input and output changed, other code are directly use the exsiting code without changes
    (1) ALS: replace `qtcs.py` with `qtcs_batch.py`
    (2) WCF-CRC: replace `run.py` with `run_batch.py`
    (3) CSD: replace `Test.java` with revised `Test.java`, replace `DataReader.java` with updated `DataReader.java` under the "util" folder
    (4) ST-Exa and Repeeling: No code has been changed, the commands to run the code are written in corresponding `.bat` file for execution  
    (5) I2ACSM: replace `Test.java` with `Test_batch.java`
    (5) TransZero_LS and TransZero_GS: all changed files and intermediate results are provided


# Cohesiveness_Output
1. Due to the large space required by the original cohesiveness output files, which exceed 1 GB, only the condensed results (averaged results) generated by the `Condense_Results.py` script are provided.